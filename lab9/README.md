# Data Exploration in Dataplex

## 1. About

Data Exploration Workbench in Dataplex (DEW) helps you interactively query fully-governed, high-quality data with one-click access to Spark SQL scripts and Jupyter notebooks. It lets you collaborate across teams with built-in publishing, sharing, and searching of coding assets.

DEW provisions, scales, and manages the serverless infrastructure required to run your Spark SQL scripts and notebooks using user credentials. You can operationalize your work with one-click serverless scheduling from the workbench.

## 2. Capabilities in Data Exploration Workbench (DEW)

### 2.1. Spark SQL Workbench
**About:**<br> 
Explore data assets with Spark SQL for the SQL savvy users.<br> 


**When to use:**<br>
Query structured data in your data lake (Cloud Storage), at scale, when you cant load the data into BigQuery managed tables


### 2.2. PySpark Jupyter Notebooks as a Service

PySpark Jupyter notebooks that can be scheduled 

**When to use:**<br>
When you prefer a notebook - <br> 
(a) to author SQL, Spark, Python etc <br> 
(b) to query BQ, structured data in your data lake, databases<br> 
(c) to not only query, but also visualize using your favorite Python visualization libraries<br> 
(d) because you also need to share it<br> 
(e) as an IDE<br> 

**Positioning by persona:**<br>
(a) Data Engineer: Spark IDE, Apache Hive Metastore IDE <br> 
(b) Data Scientist: Experimentation - preprocessing, model training, tuning, batch scoring<br> 
(c) Data Analyst: Analyze data with a mix of SQL and programmatic logic, at scale<br> 
(d) Data Product Manager: Analyze data & ideate on data products to build, analyze usage and trends with data products<br> 
(e) Data Steward: Analyze data profile, data quality, data access, audit logs and more <br> 

## 3. Terminology Levelset

### 3.1. DPMS

### 3.2. Environment

### 3.3. Default Environment

### 3.4. Session


